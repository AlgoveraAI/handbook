---
authors: [richard]
tags: [Decentralized AI, Decentralized Science, Ocean Protocol, Protocol Labs, DeSci Labs, Digital Gaia]
--- 

_[OpSci](https://opsci.io/) and Algovera (with the support of OceanDAO) are proud to announce a workshop and talks on "Decentralized AI Infrastructure for Scientific Research in Autonomous Communities" at [DeSci Berlin](https://www.desci.berlin/) on May 24th, 10 am - 11.30 am._

![solarpunk-berlin](./solarpunk-berlin.jpg)
_<center> Solarpunk Berlin by Alex Rommel </center>_

## Foreword

AI development is a complex process with many moving parts that need to come together to create real-world applications. At the moment, this work is usually performed within centralized institutions such as universities and tech companies. This has advantages for coordination, as well as providing infrastructure and capital. These organizations also provide a huge opportunity to learn from other experienced and talented individuals. 

There are also disadvantages of centralization. For example, workers within these organizations do not keep ownership of what they create. This means that any intellectual property (e.g. a language model) is controlled by a small number of people and the value generated by the models is not well distributed. Furthermore, we believe that it can result in a general [lack of diversity of research](https://twitter.com/richardblythman/status/1525858007044788224) in the space. We have seen cases where researchers work on neural networks to satisfy their organizations, despite believing that neural networks are not the most promising research direction. Finally, centralized cloud infrastructure has very high profit margins, which can price out individuals and startups.

At [Algovera](https://www.algovera.ai/), we envision a world where independent AI developers have the freedom and support to work on projects that theyâ€™re passionate about. These AI developers would keep ownership of their ideas and inventions, receive rewards based on their contributions and acquire passive income based on the value generated by their creations. To achieve this, we believe that it is necessary to push towards a decentralized AI ecosystem. This includes many different layers of the AI stack such as data and IP ownership, the underlying cloud infrastructure, funding and organization/coordination. This a massive undertaking that will require many different technologies and teams to come together. Luckily, there are many projects working towards this goal. However, we have also found that the decentalized AI space is a bit fragmented.

With this in mind, we are very excited to announce the very first decentralized AI event at [DeSci Berlin](https://www.desci.berlin/) on **May 24th, 10 am - 11.30 am**. This will bring together many leading projects with the aim of facilitating learning and collaboration. We have been hugely inspired by the energy created by real-life events in the decentralized science community, and hope to emulate this in the field of decentralized AI. You can find more information on the session, talks and workshop below. For those that would like to attend remotely, the event will be streamed and recorded. Thanks also to Shady and [OpSci](https://opsci.io/) for co-organizing. 

---

## Event Information

**Session Title**

Decentralized AI Infrastructure for Scientific Research in Autonomous Communities

**Organizers**
Shady (OpSci), Richard (Algovera)

**Session Date**
May 24th, 10am - 1130am CET

**Session Theme**

Access to the tools and resources required for studying human society, the natural world, and our collective impact on it, have been traditionally limited to those with privileged access. Currently, a fresh wave of data is being onboarded to a new open source infrastructure, opening up vast new opportunities for secondary use-cases. Digital communities all around the world can now access massive volumes of data and collaborate in real time, increasing the collective throughput of scientific research and development of real-world applications. Raw data has latent value that requires processing to extract insights and enable useful predictions, e.g. using machine learning and AI. However, this is a complex process involving many steps and moving parts. Decentralization offers potential benefits, but development of the underlying infrastructure is early-stage and fragmented. Key bottlenecks include access to compute and storage resources, tools for transparency and governance, and limitations of current intellectual property. In this session, we explore current developments in decentralized AI infrastructure, such as decentralized web storage, accessible compute markets, decentralized autonomous research communities, and knowledge artifacts as synthetic non-fungible assets - with a particular focus on open science communities.

## Session Participants

### **(1) Composable DeSci Flows Via Token-Wrapped Data & Algorithms** (Trent McConaghy, Ocean Protocol)

![trent](./trent.png)

**Bio:** *Trent McConaghy co-founded Ocean Protocol. He has worked on AI since 1997 (circuit synthesis, statistical verification), and blockchain since 2013 (incl. Token Engineering, agent-based simulation, and Ocean). He holds a PhD in EE. He's written two textbooks and 40+ peer-reviewed papers and patents.*

**Talk Abstract:** *Science is about making models to predict unseen events, in a reproducible way. It's data all the way down. Data can be raw measurements, cleaned data, features, scientific models, or predictions. Data can be algorithms to build the models. Data can be dynamically changing.*

*This talk describes how to use Ocean for composable, reproducible data flows by tokenizing data & algorithms: ERC721 data NFTs to wrap the base data/algorithms, and ERC20 datatokens as access control tokens. Compute-to-Data flows preserve privacy and control. Data & algorithms can use Web3 storage or compute.*

*Data NFTs and datatokens are the atomic building blocks. They naturally interoperate with Web3 wallets, DAOs, DEXes, and other Web3 tools. From this, we can construct many DeSci flows, from AI-training provenance to scientific model commons to algorithm marketplaces.*

### (2) **Compute over Data** (David Aronchik, Protocol Labs)

![david](./david.png)

**Bio:** *David Aronchik is the Lead of Research Development at Protocol Labs, helping, deploying and organizing our community building the next generation of the Internet. Previously, David led Open Source Machine Learning Strategy at Azure, product management for Kubernetes on behalf of Google, launched Google Kubernetes Engine, and co-founded the Kubeflow project and the SAME project. He has also worked at Microsoft, Amazon and Chef and co-founded three startups.*

### (3) **Decentralized Infrastructure for Science (**Christopher Hill, DeSci Labs)

![chris](./chris.png)

**Bio:** *Dr. Christopher Hill is a co-founder of DeSci Labs. Chris is an interdisciplinary scientist who worked at the crossroads of neuroscience, economics, and machine learning. He holds a PhD in Neuroeconomics.*

**Talk Abstract:** *Together, Protocol Labs and DeSci Labs are democratizing access to scientific infrastructure by creating technologies to promote reproducibility, replicability, and recalibrate the incentives to produce and verify new knowledge. The ability to run compute, whether for data processing or serving (e.g. microservices) is a major missing piece of the DeSci stack. By enabling spare compute power globally to be contributed to an open market of providers and scientists, the cost of compute can become accessible to all scientists, promoting global knowledge sharing.*

### **(4) Decentralized AI for Planetary Regeneration** **(**Rafael Kaufmann, Digital Gaia)

![rafael](./rafael.png)

**Bio:** *Raf is a technologist with experience encompassing physics, economics, AI, statistical and complex systems modeling, product management, entrepreneurship, and organizational development. After 6 years learning about collective intelligence and applying it to scale organizational effectiveness at Google, he co-founded Digital Gaia with the mission of building Earth's neocortex.*

**Talk Abstract:** *We are building prosthetic brains for ecosystems to support and automate decision-making in impact investment. We will give an overview of the technical architecture and network incentives, and highlight some interesting design considerations.*


### **(5) The Decentralized AI Stack** (Richard Blythman, Algovera)

![richard](./richard.png)

**Bio:** *Richard is a machine learning engineer with a research background. He co-founded Algovera to tackle issues he experienced in big tech, universities and startups around applications, funding, and the time taken to develop AI apps.*

**Talk Abstract:** *The AI stack has many components that need to come together for building useful applications, including storage, compute, marketplaces, access control, funding and organizational structure. We will outline some of the work that Algovera has been doing to decentralize and integrate various layers of the stack, as well as some of the applications being developed in our ecosystem of independent AI teams.*


## Who is Algovera?

Algovera is a community of independent AI teams creating useful AI applications. Our mission is to empower data scientists to work for themselves and keep ownership of (and monetize) their creations. We provide infrastructure that makes it easier to get from idea to an AI app deployed in the real world. We also provide opportunities for undertaking [freelance](https://docs.algovera.ai/blog/2022/01/24/Announcing%20Algovera%E2%80%99s%20Partnership%20with%20nCight%20to%20develop%20a%20medical%20image%20classification%20algorithm) work, applying for project [grants](https://docs.algovera.ai/blog/2021/12/23/Introducing%20Algovera%20AI%20x%20Web3%20Grants) and taking part in [hackathons](https://mirror.xyz/0x8b2622EEA6ca1cD84423a63DD551bAC913BAc932/Lk1S-PD3eEfxttwYFrD4yOZNmidZJzMY1kQpYEewv7Q). Join our [Discord](https://discord.com/invite/e65RuHSDS5) to find out more. 